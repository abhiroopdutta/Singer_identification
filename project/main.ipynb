{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the AudioSegment class for processing audio and the \n",
    "# split_on_silence function for separating out silent chunks.\n",
    "from pydub import AudioSegment \n",
    "from pydub.silence import split_on_silence\n",
    "import numpy as np, matplotlib.pyplot as plot, librosa, librosa.display, sklearn, sys\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "import os, _pickle as cPickle, warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting mfccs and scaling them\n",
    "def scaled_mfccs(path):\n",
    "    # Load your audio.\n",
    "    song = AudioSegment.from_file(path)\n",
    "\n",
    "    #convert the song into numpy array\n",
    "    song_array = song.get_array_of_samples()\n",
    "    song_array = np.array(song_array)\n",
    "    \n",
    "    song_array = song_array.astype(float)\n",
    "    mfccs = librosa.feature.mfcc(song_array,n_mfcc=20)\n",
    "    \n",
    "    #scaling the MFCCs such that each coefficient dimension has zero mean and unit variance\n",
    "    mfccs = sklearn.preprocessing.scale(mfccs,axis =1)\n",
    "    mfccs = mfccs.transpose()\n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ modeling completed for speaker: 32373500.gmm  with data point =  (10344, 20)\n",
      "+ modeling completed for speaker: 32449093.gmm  with data point =  (10344, 20)\n",
      "+ modeling completed for speaker: 36323632.gmm  with data point =  (10344, 20)\n",
      "+ modeling completed for speaker: 497880111.gmm  with data point =  (10344, 20)\n",
      "+ modeling completed for speaker: 498270772.gmm  with data point =  (10344, 20)\n"
     ]
    }
   ],
   "source": [
    "#training dataset location text file\n",
    "location = \"audio_files/training/\"\n",
    "dest = \"trained_models/\"\n",
    "\n",
    "\n",
    "#24 songs of 10 sec per singer, each has mfccs of size 20x?, we stack them vertically\n",
    "features = np.empty([10344, 20])\n",
    "count = 1 \n",
    "i = 0\n",
    "with open(\"train.txt\", \"r\") as training_file:\n",
    "    for path in training_file:\n",
    "        #remove leading and trailing spaces\n",
    "        path = path.strip()\n",
    "        mfccs = scaled_mfccs(location+path)\n",
    "#         np.set_printoptions(threshold=sys.maxsize)\n",
    "        \n",
    "        if(count <= 24):\n",
    "            features[i:i+431, :] = mfccs\n",
    "            i = i+431\n",
    "        if(count == 24):  \n",
    "            gmm =  GMM(n_components=8).fit(features)\n",
    "        \n",
    "            #dump the results in pickle file\n",
    "            picklefile = path.split(\"_\")[0]+\".gmm\"\n",
    "            cPickle.dump(gmm,open(dest + picklefile,'wb'))\n",
    "            print('+ modeling completed for speaker:',picklefile,\" with data point = \",features.shape)\n",
    "            \n",
    "            count = 0\n",
    "            i = 0\n",
    "        count = count+1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tdetected as -  32373500\n",
      "\tdetected as -  32373500\n",
      "\tdetected as -  32373500\n",
      "\tdetected as -  32373500\n",
      "\tdetected as -  32373500\n",
      "\tdetected as -  32373500\n",
      "\tdetected as -  32373500\n",
      "\tdetected as -  32373500\n",
      "\tdetected as -  32373500\n",
      "\tdetected as -  32373500\n",
      "\tdetected as -  32373500\n",
      "\tdetected as -  32373500\n",
      "\tdetected as -  32449093\n",
      "\tdetected as -  32449093\n",
      "\tdetected as -  32449093\n",
      "\tdetected as -  32449093\n",
      "\tdetected as -  32449093\n",
      "\tdetected as -  32449093\n",
      "\tdetected as -  32449093\n",
      "\tdetected as -  32449093\n",
      "\tdetected as -  32449093\n",
      "\tdetected as -  32449093\n",
      "\tdetected as -  32449093\n",
      "\tdetected as -  32449093\n",
      "\tdetected as -  36323632\n",
      "\tdetected as -  36323632\n",
      "\tdetected as -  36323632\n",
      "\tdetected as -  36323632\n",
      "\tdetected as -  36323632\n",
      "\tdetected as -  36323632\n",
      "\tdetected as -  36323632\n",
      "\tdetected as -  36323632\n",
      "\tdetected as -  36323632\n",
      "\tdetected as -  36323632\n",
      "\tdetected as -  36323632\n",
      "\tdetected as -  36323632\n",
      "\tdetected as -  497880111\n",
      "\tdetected as -  497880111\n",
      "\tdetected as -  497880111\n",
      "\tdetected as -  497880111\n",
      "\tdetected as -  497880111\n",
      "\tdetected as -  497880111\n",
      "\tdetected as -  497880111\n",
      "\tdetected as -  497880111\n",
      "\tdetected as -  497880111\n",
      "\tdetected as -  497880111\n",
      "\tdetected as -  497880111\n",
      "\tdetected as -  497880111\n",
      "\tdetected as -  498270772\n",
      "\tdetected as -  498270772\n",
      "\tdetected as -  498270772\n",
      "\tdetected as -  498270772\n",
      "\tdetected as -  498270772\n",
      "\tdetected as -  498270772\n",
      "\tdetected as -  498270772\n",
      "\tdetected as -  498270772\n",
      "\tdetected as -  498270772\n",
      "\tdetected as -  498270772\n",
      "\tdetected as -  498270772\n",
      "\tdetected as -  498270772\n"
     ]
    }
   ],
   "source": [
    "#path to test data \n",
    "test_location = \"audio_files/testing/\"\n",
    "\n",
    "#path to trained models\n",
    "modelpath = \"trained_models/\"\n",
    "\n",
    "#get a list of path of all the GMM model files \n",
    "gmm_files = [os.path.join(modelpath,file) for file in\n",
    "              os.listdir(modelpath) if file.endswith('.gmm')]\n",
    "\n",
    "#extract the id of the speaker corresponding to each GMM model\n",
    "speakers  = [file.split(\"/\")[-1].split(\".gmm\")[0] for file\n",
    "              in gmm_files]\n",
    "\n",
    "\n",
    "with open(\"test.txt\",\"r\") as test_paths:\n",
    "    for path in test_paths:\n",
    "        path = path.strip()\n",
    "        mfccs = scaled_mfccs(test_location+path)\n",
    "        \n",
    "        #create an empty array to store the log-likelihood corresponding to each model\n",
    "        log_likelihood = np.zeros(len(gmm_files)) \n",
    "         \n",
    "        for i in range(len(gmm_files)):\n",
    "            file = gmm_files[i]\n",
    "            gmm = cPickle.load(open(file,'rb'))  #checking with each model one by one\n",
    "            scores = np.array(gmm.score(mfccs))\n",
    "            log_likelihood[i] = scores.sum()\n",
    "        \n",
    "        #getting the index of the model giving the maximum likelihood value\n",
    "        winner = np.argmax(log_likelihood)\n",
    "        print (\"\\tdetected as - \", speakers[winner])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
